1. ### 配置[免密登陆](../../linux/配置免密登陆.md)

2. ### 下载安装jdk

3. ### 伪分布式

   1. ##### 下载安装hadoop

   2. ##### 配置文件

   ```xml
   cd $HADOOP_HOME/etc/hadoop
   
   core-site.xml
   <!-- 指定NameNode的地址 -->
   <property>
   	<name>fs.defaultFS</name>
     <value>hdfs://hadoop-pseudo:8020</value>
   </property>
   <!-- 指定hadoop数据的存储目录 -->
   <property>
     <name>hadoop.tmp.dir</name>
   	<value>/usr/local/hadoop/hadoop-3.1.4/data</value>
   </property>
   
   hdfs-site.xml
   <property>
     <name>dfs.namenode.name.dir</name>
     <value>/usr/local/hadoop/hadoop-3.1.4/hdfs/name</value>
   </property>
   <property>
       <name>dfs.datanode.data.dir</name>
       <value>/usr/local/hadoop/hadoop-3.1.4/hdfs/data</value>
   </property>
   <property>
       <name>dfs.replication</name>
       <value>1</value>
   </property>
   
   mapred-site.xml
   <property>
     <name>mapreduce.framework.name</name>
     <value>yarn</value>
   </property>
   
   yarn-site.xml
   <!-- 设置ResourceManager 域名 -->
   <property>
     <name>yarn.resourcemanager.hostname</name>
     <value>hadoop-pseudo</value>
   </property>
   <property>
     <name>yarn.nodemanager.aux-services</name>
     <value>mapreduce_shuffle</value>
   </property>
   <!-- 开启yarn.webapp.ui2 -->
   <property>
     <description>To enable RM web ui2 application.</description>
     <name>yarn.webapp.ui2.enable</name>
     <value>true</value>
   </property>
   <!-- 默认为true, 当虚拟机内存不够多时，容易超出虚拟机内存 -->
   <property>
     <name>yarn.nodemanager.vmem-check-enabled</name>
     <value>false</value>
     <description>Whether virtual memory limits will be enforced for containers.</description>
   </property>
   
   ```

   3. $HADOOP_HOME/etc/hadoop/hadoop-env.sh
      添加如下配置，

      ```shell
      JAVA_HOME=/opt/jdk/openjdk-1.8.0_92
      HADOOP_SHELL_EXECNAME=root
      ```

      

   4. 修改$HADOOP_HOME/bin/hdfs
      把HADOOP_SHELL_EXECNAME="hdfs"修改为HADOOP_SHELL_EXECNAME="root"即可

   5. 为防止启动失败，需修改start-dfs.sh、start-yarn.sh、stop-dfs.sh、stop-yarn.sh，
      修改start-dfs.sh、stop-dfs.sh，在文件头添加如下设置，

      ```
      HDFS_DATANODE_USER=root
      HDFS_DATANODE_SECURE_USER=hdfs
      HDFS_NAMENODE_USER=root
      HDFS_SECONDARYNAMENODE_USER=root
      ```

      修改start-yarn.sh、stop-yarn.sh，在文件头添加如下设置，

      ```
      YARN_RESOURCEMANAGER_USER=root
      HADOOP_SECURE_DN_USER=yarn
      YARN_NODEMANAGER_USER=root
      ```

   

4. ### 分布式

   1. docker

      本文通过使用Centos8(Docker)作为系统环境，一步步搭建出Hadoop3.1.3，其间顺便搭建java环境。

      安装包：

      hadoop-3.1.3.tar.gz 

      jdk-8u162-linux-x64.tar.gz

      为了方便管理可以创建一个**hadoop用户账号**，添加密码，增加管理员权限，

      ```
      [root@e22c6017dd9b /]# useradd hadoop
      [root@e22c6017dd9b /]# passwd hadoop
      [root@e22c6017dd9b /]# chmod -v u+w /etc/sudoers
      [root@e22c6017dd9b /]# vim /etc/sudoers #找到root ALL=(ALL) ALL 然后添加hadoop ALL=(ALL) ALL 如需新用户使用sudo时不用输密码，把最后一个ALL改为NOPASSWD:ALL即可。
      [root@e22c6017dd9b /]# chmod -v u-w /etc/sudoers
      [root@e22c6017dd9b /]# su hadoop
      [hadoop@e22c6017dd9b /]$ sudo -l
      ```

      

      ps:这里我出现了一点小问题，提示

      bash: passwd: command not found

      直接安装就好了

      ```
      [root@e22c6017dd9b /]# dnf update
      [root@e22c6017dd9b /]# dnf install passwd -y
      ```

      这里我没有找到/etc/sudoers文件，推测应该是没有安装sudo，还是一样，直接安装就好了

      ```
      [root@e22c6017dd9b /]#dnf install sudo -y
      ```

      >  看林子雨老师说的集群、单节点模式都需要用到 SSH 登陆（类似于远程登陆，你可以登录某台 Linux 主机，并且在上面运行命令），还需要安装 SSH server
      >
      > http://dblab.xmu.edu.cn/blog/2441-2/

      **安装ssh客户端和server**

      ```
      [root@e22c6017dd9b /]# yum install openssh-clients -y
      [root@e22c6017dd9b /]# yum install openssh-server -y
      [hadoop@e22c6017dd9b /]$ ssh localhost #登录本机(1)
      exit                           # 退出刚才的 ssh localhost
      cd ~/.ssh/                     # 若没有该目录，请先执行一次ssh localhost
      ssh-keygen -t rsa              # 会有提示，都按回车就可以
      cat ./id_rsa.pub >> ./authorized_keys  # 加入授权
      ```

      这里有个题外话

      ```
      # usermod -g root hadoop #这里顺便弄了下
      ```

       弄好后把宿主机上面的文件拉过去

      ```
      [root@iZwz9g27qld9va1076x1rrZ ~]# docker cp jdk-8u162-linux-x64.tar.gz  eeadbd63f1cb:/home/hadoop
      ```

      **安装java环境**

      先找地方存放好jdk文件

      ```
      cd /usr/lib
      sudo mkdir jvm #创建/usr/lib/jvm目录用来存放JDK文件
      cd ~ #进入hadoop用户的主目录
      cd home/hadoop #注意区分大小写字母，刚才已经通过FTP软件把JDK安装包jdk-8u162-linux-x64.tar.gz上传到该目录下
      sudo tar -zxvf ./jdk-8u162-linux-x64.tar.gz -C /usr/lib/jvm  #把JDK文件解压到/usr/lib/jvm目录下
      ls /usr/lib/jvm #jdk1.8.0_162目录
      ```

      

      开始配置环境

      ```
      cd ~
      vim ~/.bashrc
      ```

      找个地方贴上去

      ```
      export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162
      export JRE_HOME=${JAVA_HOME}/jre
      export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
      export PATH=${JAVA_HOME}/bin:$PATH
      ```

      现在就可以刷新一下再看看有没有成功

      ```
      [hadoop@eeadbd63f1cb jvm]$ source ~/.bashrc
      [hadoop@eeadbd63f1cb jvm]$ java -version
      java version "1.8.0_162"
      Java(TM) SE Runtime Environment (build 1.8.0_162-b12)
      Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)
      ```

       终于**开始安装Hadoop**，我不知道该不该吐槽下我竟然弄了好久前面的那些，跟配置java一样，先把文件拉过来再说

      ```
      [root@iZwz9g27qld9va1076x1rrZ ~]# docker cp hadoop-3.1.3.tar.gz  eeadbd63f1cb:/home/hadoop
      ```

      然后解压，改名，给权限

      ```
      [hadoop@eeadbd63f1cb jvm]$ sudo tar -zxf ~/hadoop-3.1.3.tar.gz -C /usr/local
      [hadoop@eeadbd63f1cb ~]$ cd /usr/local/
      [hadoop@eeadbd63f1cb local]$ sudo mv ./hadoop-3.1.3/ ./hadoop 
      [hadoop@eeadbd63f1cb local]$ sudo chown -R hadoop ./hadoop
      ```

      最后就可以检查下是否可用

      

      ```
      [hadoop@eeadbd63f1cb local]$ cd hadoop/
      [hadoop@eeadbd63f1cb hadoop]$ ./bin/hadoop version
      Hadoop 3.1.3
      Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579
      Compiled by ztang on 2019-09-12T02:47Z
      Compiled with protoc 2.5.0
      From source with checksum ec785077c385118ac91aadde5ec9799
      This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-3.1.3.jar
      ```

       

   2. 

5. 

